{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install pandas\n",
    "! pip3 install matplotlib\n",
    "! pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01525fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "churn_data = pd.read_csv(\"churn.csv\")\n",
    "churn_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command calculates the various statistics for the features.\n",
    "churn_data.describe()  \n",
    "# The following command displays the histograms for the different features.  \n",
    "# You can replace the column names to plot the histograms for other features\n",
    "churn_data.hist(['CreditScore', 'Age', 'Balance'])\n",
    "# The following command calculate the correlations among features\n",
    "churn_data.corr('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder_1 = OrdinalEncoder()\n",
    "encoder_2 = OrdinalEncoder()\n",
    "churn_data['Geography_code'] = encoder_1.fit_transform(churn_data[['Geography']])\n",
    "churn_data['Gender_code'] = encoder_2.fit_transform(churn_data[['Gender']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13011f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data.drop(columns = ['Geography','Gender','RowNumber','Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the train_test_split class for data split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the dataset into training (80%) and testing (20%).\n",
    "churn_train, churn_test = train_test_split(churn_data, test_size=0.2)\n",
    "# Split the features from the target variable \"Exited\" as it is required for model training\n",
    "# and validation later.\n",
    "churn_train_X = churn_train.loc[:, churn_train.columns != 'Exited']\n",
    "churn_train_y = churn_train['Exited']\n",
    "churn_test_X = churn_test.loc[:, churn_test.columns != 'Exited']\n",
    "churn_test_y = churn_test['Exited']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bbbbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the Random Forest algorithm to train the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "bank_churn_clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "bank_churn_clf.fit(churn_train_X, churn_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the accuracy_score class of the sklearn library to calculate the accuracy.\n",
    "from sklearn.metrics import accuracy_score\n",
    "# We use the trained model to generate predictions using the test dataset\n",
    "churn_prediction_y = bank_churn_clf.predict(churn_test_X)\n",
    "# We measure the accuracy using the accuracy_score class.\n",
    "accuracy_score(churn_test_y, churn_prediction_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88da32a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
